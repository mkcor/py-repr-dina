{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another introduction to Bayesian data analysis with PyStan\n",
    "\n",
    "### Marianne Corvellec\n",
    "\n",
    "*Institute for Globally Distributed Open Research and Education (IGDORE)*\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    Seminar organized by Alberto Antonietti\n",
    "    <br>\n",
    "    DEIB\n",
    "    <br>\n",
    "    <b>Politecnico di Milano</b>\n",
    "    <br><br>\n",
    "    (Milan, Italy)\n",
    "    <br><br>\n",
    "    October 22<small><sup>nd</sup></small>, 2018\n",
    "</center>\n",
    "\n",
    "<center><img src=\"./images/igdore_logo.png\" width=\"250\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another introduction to Bayesian inference\n",
    "\n",
    "1) Build a Bayesian statistical model\n",
    "\n",
    "| Data $\\mathcal{D}$ | Parameter $\\theta$ | |\n",
    "| --- | --- | --- |\n",
    "| ![Likelihood](./images/likelihood_0.png) | ![Prior](./images/prior_0.png) | ![Posterior](./images/posterior_0.png) |\n",
    "\n",
    "$\\quad \\textbf{likelihood} \\; p(\\mathcal{D} | \\theta)$\n",
    "$\\quad \\times \\quad \\qquad \\textbf{prior} \\; p(\\theta)  \\quad$\n",
    "$\\quad = \\quad \\textbf{posterior} \\; p(\\theta | \\mathcal{D})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2) Compute expectations\n",
    "\n",
    "$$\\mathbb{E}[a] = \\int a(\\theta) p(\\theta | \\mathcal{D}) \\mathrm{d}\\theta$$\n",
    "\n",
    "(HMC, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- Interest in Education and Assessment\n",
    "  * Learning, evaluation, survey design and analysis\n",
    "  * [The Carpentries](https://carpentries.org/assessment) (https://peer.asee.org/30960)\n",
    "  * [Rochelle E. Tractenberg](https://neurology.georgetown.edu/faculty/tractenberg)'s work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Reproducing Stan's education case study [DINA](http://mc-stan.org/users/documentation/case-studies/dina_independent.html) in Python (Seung Yeon Lee)\n",
    "- Following the format of our [SciPy 2018 paper](http://conference.scipy.org/proceedings/scipy2018/vamvourellis_corvellec.html) \"A Bayesian’s journey to a better research workflow\" (Konstantinos Vamvourellis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Stan?\n",
    "\n",
    "- It is a C++ compiled language for Bayesian statistical inference.\n",
    "- You give the ingredients $\\{ p(\\mathcal{D}|\\theta), p(\\theta) \\}$ (likelihood and prior),\n",
    "  it gives you the posterior $p(\\theta | \\mathcal{D})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In practice,\n",
    "\n",
    "- [PyStan](https://github.com/stan-dev/pystan): Python interface to Stan\n",
    "- Stan resources online\n",
    "  * Stan Manual [mc-stan.org/users/documentation](http://mc-stan.org/users/documentation)\n",
    "  * Case Studies [mc-stan.org/users/documentation/case-studies](http://mc-stan.org/users/documentation/case-studies)\n",
    "  * Forum [discourse.mc-stan.org](http://discourse.mc-stan.org)\n",
    "- Similar tool: PyMC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Context and motivation\n",
    "\n",
    "- The original work http://mc-stan.org/users/documentation/case-studies/dina_independent.html is copyrighted by Seung Yeon Lee and licensed under the 3-clause BSD and CC BY licenses (pro-sharing and attribution).\n",
    "\n",
    "- This modified work lives at https://github.com/mkcor/py-repr-dina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The DINA model (Deterministic Input, Noisy And gate) belongs to the family of cognitive diagnosis models (CDM), which are used in educational measurement.\n",
    "\n",
    "- Respondents (**students**) answer a questionnaire made of many **items**.\n",
    "\n",
    "- The goal is to estimate students’ mastery of multiple latent traits, known as attributes or **skills**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1) Scope the problem\n",
    "\n",
    "Example: Skills relate to fraction subtraction. One skill is the ability to find a common denominator. An item requiring this skill could be \"Compute $\\frac{1}{2} - \\frac{1}{3}$.\"\n",
    "- $K$ skills\n",
    "- $I$ items\n",
    "- $J$ students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Data\n",
    "\n",
    "- $J \\times I$ response matrix $Y$ where\n",
    "  $y_{ji} = 1$ if student $j$ answered item $i$ correctly, $y_{ji} = 0$ otherwise;\n",
    "- $I \\times K$ Q-matrix $Q$ where\n",
    "  $q_{ik} = 1$ if item $i$ requires skill $k$, $q_{ik} = 0$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Estimate\n",
    "\n",
    "- $J \\times K$ matrix $R$ where $r_{jk}$ is the probability for student $j$ to master skill $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- $K = 5$ skills\n",
    "- $I = 15$ items\n",
    "- $J = 536$ students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I01</th>\n",
       "      <th>I02</th>\n",
       "      <th>I03</th>\n",
       "      <th>I04</th>\n",
       "      <th>I05</th>\n",
       "      <th>I06</th>\n",
       "      <th>I07</th>\n",
       "      <th>I08</th>\n",
       "      <th>I09</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I01  I02  I03  I04  I05  I06  I07  I08  I09  I10  I11  I12  I13  I14  I15\n",
       "0    0    1    0    1    0    1    1    1    1    1    1    0    1    1    1\n",
       "1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
       "2    1    1    1    1    0    0    0    0    1    1    1    0    0    0    0\n",
       "3    1    1    1    0    0    1    1    1    1    0    1    0    1    0    1\n",
       "4    0    1    1    0    0    0    0    1    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y = pd.read_csv('./../data/responses.csv')\n",
    "Q = pd.read_csv('./../data/item_skill_Q.csv')\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK1</th>\n",
       "      <th>SK2</th>\n",
       "      <th>SK3</th>\n",
       "      <th>SK4</th>\n",
       "      <th>SK5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SK1  SK2  SK3  SK4  SK5\n",
       "0     1    0    0    0    0\n",
       "1     1    1    1    1    0\n",
       "2     1    0    0    0    0\n",
       "3     1    1    1    1    1\n",
       "4     0    0    1    0    0\n",
       "5     1    1    1    1    0\n",
       "6     1    1    1    1    0\n",
       "7     1    1    0    0    0\n",
       "8     1    0    1    0    0\n",
       "9     1    0    1    1    1\n",
       "10    1    0    1    0    0\n",
       "11    1    0    1    1    0\n",
       "12    1    1    1    1    0\n",
       "13    1    1    1    1    1\n",
       "14    1    1    1    1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matrix $\\alpha$ of skill profiles\n",
    "\n",
    "There are $C = 2^K$ possible skill profiles. Skill mastery is a latent trait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK1</th>\n",
       "      <th>SK2</th>\n",
       "      <th>SK3</th>\n",
       "      <th>SK4</th>\n",
       "      <th>SK5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SK1  SK2  SK3  SK4  SK5\n",
       "0     0    0    0    0    0\n",
       "1     0    0    0    0    1\n",
       "2     0    0    0    1    0\n",
       "3     0    0    0    1    1\n",
       "4     0    0    1    0    0\n",
       "5     0    0    1    0    1\n",
       "6     0    0    1    1    0\n",
       "7     0    0    1    1    1\n",
       "8     0    1    0    0    0\n",
       "9     0    1    0    0    1\n",
       "10    0    1    0    1    0\n",
       "11    0    1    0    1    1\n",
       "12    0    1    1    0    0\n",
       "13    0    1    1    0    1\n",
       "14    0    1    1    1    0\n",
       "15    0    1    1    1    1\n",
       "16    1    0    0    0    0\n",
       "17    1    0    0    0    1\n",
       "18    1    0    0    1    0\n",
       "19    1    0    0    1    1\n",
       "20    1    0    1    0    0\n",
       "21    1    0    1    0    1\n",
       "22    1    0    1    1    0\n",
       "23    1    0    1    1    1\n",
       "24    1    1    0    0    0\n",
       "25    1    1    0    0    1\n",
       "26    1    1    0    1    0\n",
       "27    1    1    0    1    1\n",
       "28    1    1    1    0    0\n",
       "29    1    1    1    0    1\n",
       "30    1    1    1    1    0\n",
       "31    1    1    1    1    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# http://pandas.pydata.org/pandas-docs/version/0.14/cookbook.html#creating-example-data\n",
    "def expand_grid(data_dict):\n",
    "    rows = itertools.product(*data_dict.values())\n",
    "    return pd.DataFrame.from_records(rows, columns=data_dict.keys()) \n",
    "\n",
    "alpha = expand_grid(\n",
    "    {'SK1': [0, 1],\n",
    "     'SK2': [0, 1],\n",
    "     'SK3': [0, 1],\n",
    "     'SK4': [0, 1],\n",
    "     'SK5': [0, 1]}\n",
    ")\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = Q.shape[0]\n",
    "J = y.shape[0]\n",
    "K = Q.shape[1]\n",
    "\n",
    "assert y.shape[1] == I\n",
    "assert alpha.shape[1] == K\n",
    "\n",
    "C = 2**K\n",
    "assert alpha.shape[0] == C\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "From $\\alpha$ and $Q$, we can compute the global mastery indicator $\\xi$. We are still at the latent level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Matrix $\\xi$ as global mastery indicator\n",
    "\n",
    "\n",
    "$\\xi$ is $I \\times C$.\n",
    "For each item $i$, a given skill profile $c$ either masters all corresponding skills ($\\xi_{ic} = 1$) or\n",
    "does not ($\\xi_{ic} = 0$).\n",
    "\n",
    "$$\\xi_{ic} = \\prod_{k = 1}^{K} \\alpha_{ck}^{q_{ik}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Toy alpha and Q matrices](./images/xi_toy_0.jpg)\n",
    "![Building toy global mastery indicator](./images/xi_toy_1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xi = np.ones((I, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile in range(xi.shape[1]):\n",
    "    for item in range(xi.shape[0]):\n",
    "        for skill in range(alpha.shape[1]):\n",
    "            xi[item, profile] *= alpha.iloc[profile, skill] ** Q.iloc[item, skill]\n",
    "# \"Vectorized is better than an explicit loop\"... Sorry!\n",
    "# Readability matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xi.max() == 1\n",
    "assert xi.min() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, a student might get item $i$ right even though they do not master all corresponding skills (guessing, $g_i$).\n",
    "Likewise, they might get item $i$ wrong even if they do master all corresponding skills (slipping, $s_i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, the probability that item $i$ be responded correctly by a student with (latent) skill profile $c$\n",
    "is given by: \n",
    "\n",
    "$$\\pi_{ic} = (1 - s_i)^{\\xi_{ic}} g_i^{(1 - \\xi_{ic})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2) Specify model, likelihood, and priors\n",
    "\n",
    "We see the model as a data generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {\n",
      "  int<lower=1> I;\t\t\t// # of items\n",
      "  int<lower=1> J;\t\t\t// # of respondents\t\n",
      "  int<lower=1> K;\t\t\t// # of attributes\n",
      "  int<lower=1> C;\t\t\t// # of attribute profiles (latent classes)\t\n",
      "  matrix[J,I] y;\t\t\t// response matrix\n",
      "  matrix[C,K] alpha;\t\t// attribute profile matrix\n",
      "  matrix[I,C] xi;\t\t\t// the global attribute mastery indicator (product of alpha^q-element)\n",
      "}\n",
      "\n",
      "parameters {\n",
      "  simplex[C] nu; \t\t\t\t\t    // probabilities of latent class membership\n",
      "  real<lower=0,upper=1> slip[I];\t\t// slip parameter\t\n",
      "  real<lower=0,upper=1> guess[I];\t\t// guess parameter\n",
      "}\n",
      "\n",
      "transformed parameters {\n",
      "  vector[C] log_nu = log(nu);\n",
      "}\n",
      "\n",
      "model {\n",
      "  real ps[C];\t\t\t\t// temp for log component densities\n",
      "  matrix[I,C] pi;\n",
      "  real log_items[I];\n",
      "  slip ~ beta(5,25);\n",
      "  guess ~ beta(5,25);\n",
      "  for (c in 1:C){\n",
      "    for (i in 1:I){\n",
      "      pi[i,c] = (1 - slip[i])^xi[i,c] * guess[i]^(1 - xi[i,c]);\n",
      "    }\n",
      "  }\n",
      "  for (j in 1:J){\n",
      "    for (c in 1:C){\n",
      "      for (i in 1:I){\n",
      "        log_items[i] = y[j,i] * log(pi[i,c]) + (1 - y[j,i]) * log(1 - pi[i,c]);\n",
      "      }\n",
      "      ps[c] = log_nu[c] + sum(log_items);\t\n",
      "    }\n",
      "    target += log_sum_exp(ps);\n",
      "  }\n",
      "}\n",
      "\n",
      "generated quantities {\n",
      "  matrix[J,C] prob_resp_class;\t\t// posterior probabilities of respondent j being in latent class c \n",
      "  matrix[J,K] prob_resp_attr;\t\t// posterior probabilities of respondent j being a master of attribute k \n",
      "  matrix[I,C] pi;\n",
      "  real log_items[I];\n",
      "  row_vector[C] prob_joint;\n",
      "  real prob_attr_class[C];\n",
      "  for (c in 1:C){\n",
      "    for (i in 1:I){\n",
      "      pi[i,c] = (1 - slip[i])^xi[i,c] * guess[i]^(1 - xi[i,c]);\n",
      "    }\n",
      "  }\n",
      "  for (j in 1:J){\n",
      "    for (c in 1:C){\n",
      "      for (i in 1:I){\n",
      "        log_items[i] = y[j,i] * log(pi[i,c]) + (1 - y[j,i]) * log(1 - pi[i,c]);\n",
      "      }\n",
      "      prob_joint[c] = nu[c] * exp(sum(log_items));\n",
      "    }\n",
      "    prob_resp_class[j] = prob_joint/sum(prob_joint);\n",
      "  }\n",
      "  for (j in 1:J){\n",
      "    for (k in 1:K){\n",
      "      for (c in 1:C){\n",
      "        prob_attr_class[c] = prob_resp_class[j,c] * alpha[c,k];\n",
      "      }\t\t\n",
      "      prob_resp_attr[j,k] = sum(prob_attr_class);\n",
      "    }\n",
      "  }\t\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('models/dina_nostructure.stan', 'r') as file:\n",
    "    model_spec = file.read()\n",
    "    print(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " log(nu);\n",
      "}\n",
      "\n",
      "model {\n",
      "  real ps[C];\t\t\t\t// temp for log component densities\n",
      "  matrix[I,C] pi;\n",
      "  real log_items[I];\n",
      "  slip ~ beta(5,25);\n",
      "  guess ~ beta(5,25);\n",
      "  for (c in 1:C){\n",
      "    for (i in 1:I){\n",
      "      pi[i,c] = (1 - slip[i])^xi[i,c] * guess[i]^(1 - xi[i,c]);\n",
      "    }\n",
      "  }\n",
      "  for (j in 1:J){\n",
      "    for (c in 1:C){\n",
      "      for (i in 1:I){\n",
      "        log_items[i] = y[j,i] * log(pi[i,c]) + (1 - y[j,i]) * log(1 - pi[i,c]);\n",
      "      }\n",
      "      ps[c] = log_nu[c] + sum(log_items);\t\n",
      "    }\n",
      "    target += log_sum_exp(ps);\n",
      "  }\n",
      "}\n",
      "\n",
      "generated quantities {\n",
      "  matrix[J,C] prob_resp_class;\t\t// posterior probabilities of respondent j being in latent class c \n",
      "  matrix[J,K] prob_resp_attr;\t\t// posterior probabilities of respondent j being a master of attribute k \n",
      "  matrix[I,C] pi;\n",
      "  real log_items[I];\n",
      "  row_vector[C] prob_joint;\n",
      "  real prob_attr_class[C];\n",
      "  for (c in 1:C){\n",
      "    for (i in 1:I){\n",
      "      pi[i,c] = (1 - slip[i])^xi[i,c] * guess[i]^(1 - xi[i,c]);\n",
      "    }\n",
      "  }\n",
      "  for (j in 1:J){\n",
      "    for (c in 1:C){\n",
      "      for (i in 1:I){\n",
      "        log_items[i] = y[j,i] * log(pi[i,c]) + (1 - y[j,i]) * log(1 - pi[i,c]);\n",
      "      }\n",
      "      prob_joint[c] = nu[c] * exp(sum(log_items));\n",
      "    }\n",
      "    prob_resp_class[j] = prob_joint/sum(prob_joint);\n",
      "  }\n",
      "  for (j in 1:J){\n",
      "    for (k in 1:K){\n",
      "      for (c in 1:C){\n",
      "        prob_attr_class[c] = prob_resp_class[j,c] * alpha[c,k];\n",
      "      }\t\t\n",
      "      prob_resp_attr[j,k] = sum(prob_attr_class);\n",
      "    }\n",
      "  }\t\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_spec[int(len(model_spec)/3.3):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pystan as stan\n",
    "\n",
    "stan.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_3f654cbe043a670df0504931f5ee3db8 NOW.\n",
      "INFO:pystan:OS: linux, Python: 3.7.0 (default, Oct  9 2018, 10:31:47) \n",
      "[GCC 7.3.0], Cython 0.28.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /tmp/tmpjc5d1rx4/stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214.pyx because it changed.\n",
      "[1/1] Cythonizing /tmp/tmpjc5d1rx4/stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214.pyx\n",
      "building 'stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214' extension\n",
      "creating /tmp/tmpjc5d1rx4/tmp\n",
      "creating /tmp/tmpjc5d1rx4/tmp/tmpjc5d1rx4\n",
      "/home/marianne/miniconda3/envs/dina/bin/x86_64-conda_cos6-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -fPIC -DBOOST_RESULT_OF_USE_TR1 -DBOOST_NO_DECLTYPE -DBOOST_DISABLE_ASSERTS -I/tmp/tmpjc5d1rx4 -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/pystan -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/pystan/stan/src -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/pystan/stan/lib/stan_math -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/pystan/stan/lib/stan_math/lib/eigen_3.3.3 -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/pystan/stan/lib/stan_math/lib/boost_1.66.0 -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/pystan/stan/lib/stan_math/lib/sundials_3.1.0/include -I/home/marianne/miniconda3/envs/dina/lib/python3.7/site-packages/numpy/core/include -I/home/marianne/miniconda3/envs/dina/include/python3.7m -c /tmp/tmpjc5d1rx4/stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214.cpp -o /tmp/tmpjc5d1rx4/tmp/tmpjc5d1rx4/stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214.o -O2 -ftemplate-depth-256 -Wno-unused-function -Wno-uninitialized -std=c++11\n",
      "/home/marianne/miniconda3/envs/dina/bin/x86_64-conda_cos6-linux-gnu-c++ -pthread -shared -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,/home/marianne/miniconda3/envs/dina/lib -L/home/marianne/miniconda3/envs/dina/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,/home/marianne/miniconda3/envs/dina/lib -L/home/marianne/miniconda3/envs/dina/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 /tmp/tmpjc5d1rx4/tmp/tmpjc5d1rx4/stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214.o -o /tmp/tmpjc5d1rx4/stanfit4anon_model_3f654cbe043a670df0504931f5ee3db8_4977506116119766214.cpython-37m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "sm = stan.StanModel(model_code=model_spec, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3) Generate synthetic data\n",
    "\n",
    "Let us simulate data generation for $20$ items, $5$ skills, and $500$ students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_s = 20  # items\n",
    "K_s = 5  # skills\n",
    "Q_s = np.zeros((I_s, K_s))\n",
    "\n",
    "J_s = 500  # students\n",
    "C_s = C  # profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_s[[1, 4, 5, 6, 14, 18], 0] = 1\n",
    "Q_s[[3, 6, 8, 9, 10, 12, 13], 1] = 1\n",
    "Q_s[15:20, 1] = 1\n",
    "Q_s[[4, 5, 12], 2] = 1\n",
    "Q_s[1:3, 2] = 1\n",
    "Q_s[[2, 3, 7, 9, 10], 3] = 1\n",
    "Q_s[16:20, 3] = 1\n",
    "Q_s[[1, 3, 4, 9, 11, 18, 19], 4] = 1\n",
    "# Watch out: Array slicing != DataFrame slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 1.],\n",
       "       [0., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [1., 1., 0., 1., 1.],\n",
       "       [0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK1</th>\n",
       "      <th>SK2</th>\n",
       "      <th>SK3</th>\n",
       "      <th>SK4</th>\n",
       "      <th>SK5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SK1  SK2  SK3  SK4  SK5\n",
       "0     0    0    0    0    0\n",
       "1     0    0    0    0    1\n",
       "2     0    0    0    1    0\n",
       "3     0    0    0    1    1\n",
       "4     0    0    1    0    0\n",
       "5     0    0    1    0    1\n",
       "6     0    0    1    1    0\n",
       "7     0    0    1    1    1\n",
       "8     0    1    0    0    0\n",
       "9     0    1    0    0    1\n",
       "10    0    1    0    1    0\n",
       "11    0    1    0    1    1\n",
       "12    0    1    1    0    0\n",
       "13    0    1    1    0    1\n",
       "14    0    1    1    1    0\n",
       "15    0    1    1    1    1\n",
       "16    1    0    0    0    0\n",
       "17    1    0    0    0    1\n",
       "18    1    0    0    1    0\n",
       "19    1    0    0    1    1\n",
       "20    1    0    1    0    0\n",
       "21    1    0    1    0    1\n",
       "22    1    0    1    1    0\n",
       "23    1    0    1    1    1\n",
       "24    1    1    0    0    0\n",
       "25    1    1    0    0    1\n",
       "26    1    1    0    1    0\n",
       "27    1    1    0    1    1\n",
       "28    1    1    1    0    0\n",
       "29    1    1    1    0    1\n",
       "30    1    1    1    1    0\n",
       "31    1    1    1    1    1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_s = alpha\n",
    "alpha_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "alpha_prob = np.array([0.01344, 0.00576, 0.02016, 0.00864, 0.05376,\n",
    "                       0.02304, 0.08064, 0.03456, 0.00336, 0.00144,\n",
    "                       0.00504, 0.00216, 0.01344, 0.00576, 0.02016,\n",
    "                       0.00864, 0.03136, 0.01344, 0.04704, 0.02016,\n",
    "                       0.12544, 0.05376, 0.18816, 0.08064, 0.00784,\n",
    "                       0.00336, 0.01176, 0.00504, 0.03136, 0.01344,\n",
    "                       0.04704, 0.02016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK1</th>\n",
       "      <th>SK2</th>\n",
       "      <th>SK3</th>\n",
       "      <th>SK4</th>\n",
       "      <th>SK5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SK1  SK2  SK3  SK4  SK5\n",
       "6     0    0    1    1    0\n",
       "14    0    1    1    1    0\n",
       "31    1    1    1    1    1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate actual skill profiles\n",
    "A = alpha_s.sample(J_s, replace=True, weights=alpha_prob)\n",
    "A.head(3)\n",
    "# TODO Seed!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK1</th>\n",
       "      <th>SK2</th>\n",
       "      <th>SK3</th>\n",
       "      <th>SK4</th>\n",
       "      <th>SK5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.471403</td>\n",
       "      <td>0.410538</td>\n",
       "      <td>0.410538</td>\n",
       "      <td>0.479892</td>\n",
       "      <td>0.444404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SK1         SK2         SK3         SK4         SK5\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000\n",
       "mean     0.668000    0.214000    0.786000    0.642000    0.270000\n",
       "std      0.471403    0.410538    0.410538    0.479892    0.444404\n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    0.000000    1.000000    0.000000    0.000000\n",
       "50%      1.000000    0.000000    1.000000    1.000000    0.000000\n",
       "75%      1.000000    0.000000    1.000000    1.000000    1.000000\n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "slip_s = np.array([15, 16, 9, 14, 19, 12, 22, 16, 14, 26, 12, 18, 20, 13, 9, 29, 30, 24, 9, 27]) * 0.01\n",
    "guess_s = np.array([9, 15, 12, 20, 8, 10, 17, 25, 28, 15, 7, 27, 10, 5, 25, 13, 25, 17, 11, 16]) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global mastery indicator for students (actual profiles)\n",
    "xi_s = np.ones((I_s, J_s))\n",
    "\n",
    "for profile in range(J_s):\n",
    "    for item in range(I_s):\n",
    "        for skill in range(K_s):\n",
    "            xi_s[item, profile] *= A.iloc[profile, skill] ** Q_s[item, skill]\n",
    "# Watch out: Array indexing != DataFrame indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xi_s.max() == 1\n",
    "assert xi_s.min() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the actual mastery of skills by these 500 (synthetic) students, we can generate the probability for them to answer items correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pi_s = np.ones((I_s, J_s))\n",
    "y_s = np.ones((J_s, I_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile in range(J_s):\n",
    "    for item in range(I_s):\n",
    "        pi_s[item, profile] = (1 - slip_s[item])**xi_s[item, profile] * guess_s[item]**(1 - xi_s[item, profile])\n",
    "        # Sample responses (data) from Bernoulli distribution with success probability above\n",
    "        y_s[profile, item] = np.random.binomial(1, pi_s[item, profile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model requires the (class) profile-based global mastery indicator $\\xi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_class_s = np.ones((I_s, C_s))\n",
    "\n",
    "for profile in range(C_s):\n",
    "    for item in range(I_s):\n",
    "        for skill in range(K_s):\n",
    "            xi_class_s[item, profile] *= alpha.iloc[profile, skill] ** Q_s[item, skill]\n",
    "# It would be about time to write a function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4) Fit model to the synthetic data\n",
    "\n",
    "Pass data to model via a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "synt_data = {\n",
    "    'I': I_s,\n",
    "    'J': J_s,\n",
    "    'K': K_s,\n",
    "    'C': C_s,\n",
    "    'y': y_s,\n",
    "    'alpha': alpha_s, \n",
    "    'xi': xi_class_s\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[1] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[3] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[5] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[7] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[9] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[11] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[13] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[15] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[17] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[19] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[21] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[23] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[25] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[27] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[29] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[31] is nan!\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[1] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[3] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[5] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[7] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[9] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[11] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[13] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[15] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[17] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[19] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[21] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[23] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[25] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[27] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[29] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[31] is nan!\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    }
   ],
   "source": [
    "fit_synt = sm.sampling(data=synt_data, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_3f654cbe043a670df0504931f5ee3db8.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "            mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "guess[1]    0.17  1.3e-3   0.07   0.06   0.12   0.16   0.21   0.31   2502    1.0\n",
      "guess[2]    0.14  3.7e-4   0.02    0.1   0.12   0.14   0.15   0.17   2405    1.0\n",
      "guess[3]    0.15  7.5e-4   0.03   0.08   0.12   0.14   0.17   0.21   1994    1.0\n",
      "guess[4]    0.23  3.6e-4   0.02   0.19   0.21   0.23   0.24   0.27   2607    1.0\n",
      "guess[5]    0.09  3.2e-4   0.02   0.06   0.08   0.09    0.1   0.13   2477    1.0\n",
      "guess[6]    0.08  5.4e-4   0.03   0.04   0.06   0.08    0.1   0.14   2449    1.0\n",
      "guess[7]    0.16  3.6e-4   0.02   0.13   0.15   0.16   0.18    0.2   2513    1.0\n",
      "guess[8]    0.25  9.9e-4   0.04   0.16   0.22   0.25   0.28   0.34   1975    1.0\n",
      "guess[9]    0.25  4.6e-4   0.02   0.21   0.24   0.25   0.27   0.29   2171    1.0\n",
      "guess[10]   0.13  2.9e-4   0.02    0.1   0.12   0.13   0.14   0.16   2714    1.0\n",
      "guess[11]   0.09  2.7e-4   0.01   0.07   0.08   0.09    0.1   0.12   2585    1.0\n",
      "guess[12]   0.23  7.4e-4   0.03   0.17   0.21   0.23   0.25   0.29   1628    1.0\n",
      "guess[13]   0.12  3.0e-4   0.02   0.09   0.11   0.12   0.13   0.16   2718    1.0\n",
      "guess[14]   0.06  2.5e-4   0.01   0.04   0.05   0.06   0.07   0.09   3051    1.0\n",
      "guess[15]   0.21  1.2e-3   0.05   0.11   0.18   0.21   0.25   0.32   1747    1.0\n",
      "guess[16]   0.17  3.8e-4   0.02   0.14   0.16   0.17   0.18   0.21   2320    1.0\n",
      "guess[17]   0.25  4.3e-4   0.02   0.22   0.24   0.25   0.27    0.3   2166    1.0\n",
      "guess[18]   0.17  3.3e-4   0.02   0.14   0.16   0.17   0.18   0.21   2850    1.0\n",
      "guess[19]   0.13  2.8e-4   0.01    0.1   0.12   0.13   0.14   0.16   2769    1.0\n",
      "guess[20]   0.17  3.2e-4   0.02   0.14   0.16   0.17   0.18    0.2   2812    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sun Oct 21 22:16:36 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(stan.misc.stansummary(fit_synt, pars=['guess']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model fit checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09, 0.15, 0.12, 0.2 , 0.08])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_s[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples_synt = fit_synt.extract(permuted=True)\n",
    "df = pd.DataFrame(post_samples_synt['guess'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167184</td>\n",
       "      <td>0.151159</td>\n",
       "      <td>0.110023</td>\n",
       "      <td>0.241166</td>\n",
       "      <td>0.091021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209224</td>\n",
       "      <td>0.157752</td>\n",
       "      <td>0.113288</td>\n",
       "      <td>0.218415</td>\n",
       "      <td>0.098927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193565</td>\n",
       "      <td>0.139308</td>\n",
       "      <td>0.123642</td>\n",
       "      <td>0.253708</td>\n",
       "      <td>0.091815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.158430</td>\n",
       "      <td>0.145637</td>\n",
       "      <td>0.230306</td>\n",
       "      <td>0.084328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107701</td>\n",
       "      <td>0.118938</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.186522</td>\n",
       "      <td>0.101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.175214</td>\n",
       "      <td>0.128321</td>\n",
       "      <td>0.108411</td>\n",
       "      <td>0.241014</td>\n",
       "      <td>0.133247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.146329</td>\n",
       "      <td>0.126774</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.248730</td>\n",
       "      <td>0.086220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.242501</td>\n",
       "      <td>0.164853</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.238208</td>\n",
       "      <td>0.073283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.204161</td>\n",
       "      <td>0.151795</td>\n",
       "      <td>0.175449</td>\n",
       "      <td>0.243246</td>\n",
       "      <td>0.084360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.171837</td>\n",
       "      <td>0.160474</td>\n",
       "      <td>0.144341</td>\n",
       "      <td>0.204017</td>\n",
       "      <td>0.109716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.235393</td>\n",
       "      <td>0.172048</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>0.210908</td>\n",
       "      <td>0.096264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.073619</td>\n",
       "      <td>0.161470</td>\n",
       "      <td>0.140052</td>\n",
       "      <td>0.211295</td>\n",
       "      <td>0.089945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.125097</td>\n",
       "      <td>0.132614</td>\n",
       "      <td>0.210235</td>\n",
       "      <td>0.215152</td>\n",
       "      <td>0.095709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.092658</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>0.145454</td>\n",
       "      <td>0.205917</td>\n",
       "      <td>0.115577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.167821</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>0.114502</td>\n",
       "      <td>0.239838</td>\n",
       "      <td>0.076266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.133864</td>\n",
       "      <td>0.160004</td>\n",
       "      <td>0.167291</td>\n",
       "      <td>0.228275</td>\n",
       "      <td>0.100288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.297778</td>\n",
       "      <td>0.117607</td>\n",
       "      <td>0.112346</td>\n",
       "      <td>0.247891</td>\n",
       "      <td>0.108096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.063486</td>\n",
       "      <td>0.118940</td>\n",
       "      <td>0.144760</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>0.091142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.177650</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.142820</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.086543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.239737</td>\n",
       "      <td>0.163021</td>\n",
       "      <td>0.146305</td>\n",
       "      <td>0.238566</td>\n",
       "      <td>0.120802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.128327</td>\n",
       "      <td>0.139512</td>\n",
       "      <td>0.132953</td>\n",
       "      <td>0.249923</td>\n",
       "      <td>0.093713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.144348</td>\n",
       "      <td>0.143038</td>\n",
       "      <td>0.192891</td>\n",
       "      <td>0.229969</td>\n",
       "      <td>0.072401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.182348</td>\n",
       "      <td>0.117425</td>\n",
       "      <td>0.130297</td>\n",
       "      <td>0.256893</td>\n",
       "      <td>0.091653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.143280</td>\n",
       "      <td>0.178589</td>\n",
       "      <td>0.245565</td>\n",
       "      <td>0.089211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.158736</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>0.154576</td>\n",
       "      <td>0.220254</td>\n",
       "      <td>0.127207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.191087</td>\n",
       "      <td>0.136105</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>0.234251</td>\n",
       "      <td>0.099315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.228289</td>\n",
       "      <td>0.121323</td>\n",
       "      <td>0.142441</td>\n",
       "      <td>0.206730</td>\n",
       "      <td>0.098718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.237994</td>\n",
       "      <td>0.151725</td>\n",
       "      <td>0.147414</td>\n",
       "      <td>0.271275</td>\n",
       "      <td>0.114442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.087710</td>\n",
       "      <td>0.129115</td>\n",
       "      <td>0.125018</td>\n",
       "      <td>0.204999</td>\n",
       "      <td>0.077443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.211940</td>\n",
       "      <td>0.172418</td>\n",
       "      <td>0.148302</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>0.083233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.120930</td>\n",
       "      <td>0.117093</td>\n",
       "      <td>0.200681</td>\n",
       "      <td>0.239764</td>\n",
       "      <td>0.112040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.322101</td>\n",
       "      <td>0.135429</td>\n",
       "      <td>0.124952</td>\n",
       "      <td>0.233183</td>\n",
       "      <td>0.110351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.172630</td>\n",
       "      <td>0.113313</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>0.209927</td>\n",
       "      <td>0.113721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.202502</td>\n",
       "      <td>0.115046</td>\n",
       "      <td>0.188387</td>\n",
       "      <td>0.211978</td>\n",
       "      <td>0.082928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.067118</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.109067</td>\n",
       "      <td>0.215829</td>\n",
       "      <td>0.075961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.067488</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.177224</td>\n",
       "      <td>0.207833</td>\n",
       "      <td>0.088784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.108765</td>\n",
       "      <td>0.117388</td>\n",
       "      <td>0.183063</td>\n",
       "      <td>0.206840</td>\n",
       "      <td>0.072949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.108974</td>\n",
       "      <td>0.126206</td>\n",
       "      <td>0.100561</td>\n",
       "      <td>0.222723</td>\n",
       "      <td>0.080179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.306215</td>\n",
       "      <td>0.154042</td>\n",
       "      <td>0.139838</td>\n",
       "      <td>0.251835</td>\n",
       "      <td>0.099578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.157127</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>0.117573</td>\n",
       "      <td>0.236989</td>\n",
       "      <td>0.106192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.105774</td>\n",
       "      <td>0.127599</td>\n",
       "      <td>0.171395</td>\n",
       "      <td>0.230736</td>\n",
       "      <td>0.092644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.139994</td>\n",
       "      <td>0.164503</td>\n",
       "      <td>0.219936</td>\n",
       "      <td>0.130996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.168008</td>\n",
       "      <td>0.142026</td>\n",
       "      <td>0.138361</td>\n",
       "      <td>0.236427</td>\n",
       "      <td>0.109615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0.193039</td>\n",
       "      <td>0.117245</td>\n",
       "      <td>0.130229</td>\n",
       "      <td>0.202999</td>\n",
       "      <td>0.084365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.121596</td>\n",
       "      <td>0.175956</td>\n",
       "      <td>0.190329</td>\n",
       "      <td>0.242292</td>\n",
       "      <td>0.104767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.060705</td>\n",
       "      <td>0.168891</td>\n",
       "      <td>0.109480</td>\n",
       "      <td>0.232109</td>\n",
       "      <td>0.094541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.227358</td>\n",
       "      <td>0.124041</td>\n",
       "      <td>0.166361</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.086296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.145226</td>\n",
       "      <td>0.091881</td>\n",
       "      <td>0.143828</td>\n",
       "      <td>0.216681</td>\n",
       "      <td>0.093501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.107168</td>\n",
       "      <td>0.115606</td>\n",
       "      <td>0.209484</td>\n",
       "      <td>0.251150</td>\n",
       "      <td>0.082195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.201352</td>\n",
       "      <td>0.130985</td>\n",
       "      <td>0.157865</td>\n",
       "      <td>0.214932</td>\n",
       "      <td>0.091589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.250728</td>\n",
       "      <td>0.141983</td>\n",
       "      <td>0.147969</td>\n",
       "      <td>0.233326</td>\n",
       "      <td>0.084831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.095002</td>\n",
       "      <td>0.141149</td>\n",
       "      <td>0.121682</td>\n",
       "      <td>0.234052</td>\n",
       "      <td>0.089318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.116251</td>\n",
       "      <td>0.149395</td>\n",
       "      <td>0.099265</td>\n",
       "      <td>0.242331</td>\n",
       "      <td>0.097316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.087339</td>\n",
       "      <td>0.130196</td>\n",
       "      <td>0.120416</td>\n",
       "      <td>0.206350</td>\n",
       "      <td>0.086504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.085738</td>\n",
       "      <td>0.135962</td>\n",
       "      <td>0.118514</td>\n",
       "      <td>0.198792</td>\n",
       "      <td>0.095243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.185793</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.147164</td>\n",
       "      <td>0.229760</td>\n",
       "      <td>0.078787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.079772</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.227938</td>\n",
       "      <td>0.085236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.126679</td>\n",
       "      <td>0.117087</td>\n",
       "      <td>0.220492</td>\n",
       "      <td>0.120849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.208224</td>\n",
       "      <td>0.126838</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.206575</td>\n",
       "      <td>0.121674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.083879</td>\n",
       "      <td>0.170116</td>\n",
       "      <td>0.194931</td>\n",
       "      <td>0.240404</td>\n",
       "      <td>0.102626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4\n",
       "0     0.167184  0.151159  0.110023  0.241166  0.091021\n",
       "1     0.209224  0.157752  0.113288  0.218415  0.098927\n",
       "2     0.193565  0.139308  0.123642  0.253708  0.091815\n",
       "3     0.190031  0.158430  0.145637  0.230306  0.084328\n",
       "4     0.107701  0.118938  0.228948  0.186522  0.101282\n",
       "5     0.175214  0.128321  0.108411  0.241014  0.133247\n",
       "6     0.146329  0.126774  0.148772  0.248730  0.086220\n",
       "7     0.242501  0.164853  0.193500  0.238208  0.073283\n",
       "8     0.204161  0.151795  0.175449  0.243246  0.084360\n",
       "9     0.171837  0.160474  0.144341  0.204017  0.109716\n",
       "10    0.235393  0.172048  0.143325  0.210908  0.096264\n",
       "11    0.073619  0.161470  0.140052  0.211295  0.089945\n",
       "12    0.125097  0.132614  0.210235  0.215152  0.095709\n",
       "13    0.092658  0.121688  0.145454  0.205917  0.115577\n",
       "14    0.167821  0.140892  0.114502  0.239838  0.076266\n",
       "15    0.133864  0.160004  0.167291  0.228275  0.100288\n",
       "16    0.297778  0.117607  0.112346  0.247891  0.108096\n",
       "17    0.063486  0.118940  0.144760  0.240571  0.091142\n",
       "18    0.177650  0.136900  0.142820  0.225024  0.086543\n",
       "19    0.239737  0.163021  0.146305  0.238566  0.120802\n",
       "20    0.128327  0.139512  0.132953  0.249923  0.093713\n",
       "21    0.144348  0.143038  0.192891  0.229969  0.072401\n",
       "22    0.182348  0.117425  0.130297  0.256893  0.091653\n",
       "23    0.053811  0.143280  0.178589  0.245565  0.089211\n",
       "24    0.158736  0.140060  0.154576  0.220254  0.127207\n",
       "25    0.191087  0.136105  0.152255  0.234251  0.099315\n",
       "26    0.228289  0.121323  0.142441  0.206730  0.098718\n",
       "27    0.237994  0.151725  0.147414  0.271275  0.114442\n",
       "28    0.087710  0.129115  0.125018  0.204999  0.077443\n",
       "29    0.211940  0.172418  0.148302  0.213135  0.083233\n",
       "...        ...       ...       ...       ...       ...\n",
       "1970  0.120930  0.117093  0.200681  0.239764  0.112040\n",
       "1971  0.322101  0.135429  0.124952  0.233183  0.110351\n",
       "1972  0.172630  0.113313  0.180128  0.209927  0.113721\n",
       "1973  0.202502  0.115046  0.188387  0.211978  0.082928\n",
       "1974  0.067118  0.109755  0.109067  0.215829  0.075961\n",
       "1975  0.067488  0.107735  0.177224  0.207833  0.088784\n",
       "1976  0.108765  0.117388  0.183063  0.206840  0.072949\n",
       "1977  0.108974  0.126206  0.100561  0.222723  0.080179\n",
       "1978  0.306215  0.154042  0.139838  0.251835  0.099578\n",
       "1979  0.157127  0.124566  0.117573  0.236989  0.106192\n",
       "1980  0.105774  0.127599  0.171395  0.230736  0.092644\n",
       "1981  0.255357  0.139994  0.164503  0.219936  0.130996\n",
       "1982  0.168008  0.142026  0.138361  0.236427  0.109615\n",
       "1983  0.193039  0.117245  0.130229  0.202999  0.084365\n",
       "1984  0.121596  0.175956  0.190329  0.242292  0.104767\n",
       "1985  0.060705  0.168891  0.109480  0.232109  0.094541\n",
       "1986  0.227358  0.124041  0.166361  0.236882  0.086296\n",
       "1987  0.145226  0.091881  0.143828  0.216681  0.093501\n",
       "1988  0.107168  0.115606  0.209484  0.251150  0.082195\n",
       "1989  0.201352  0.130985  0.157865  0.214932  0.091589\n",
       "1990  0.250728  0.141983  0.147969  0.233326  0.084831\n",
       "1991  0.095002  0.141149  0.121682  0.234052  0.089318\n",
       "1992  0.116251  0.149395  0.099265  0.242331  0.097316\n",
       "1993  0.087339  0.130196  0.120416  0.206350  0.086504\n",
       "1994  0.085738  0.135962  0.118514  0.198792  0.095243\n",
       "1995  0.185793  0.144000  0.147164  0.229760  0.078787\n",
       "1996  0.079772  0.128378  0.161596  0.227938  0.085236\n",
       "1997  0.085515  0.126679  0.117087  0.220492  0.120849\n",
       "1998  0.208224  0.126838  0.148305  0.206575  0.121674\n",
       "1999  0.083879  0.170116  0.194931  0.240404  0.102626\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAHVCAYAAAAdGumXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X2QXXWZ6PvvQ4jTIFGGBDCkCR2cVIBhVEIj1AE98SVnICpcQBDLGRGBOEcspfRWEbmU4txyhpqrHrG0lOA4Ao4gKEpExAl4oqWlQngpQTSHHEXYJiMhJQQIIS8894+92tMknfTq3nvttXvv76dqV6/16/Xy5EfIs38v67ciM5EkSb1lr7oDkCRJ7WeClySpB5ngJUnqQSZ4SZJ6kAlekqQeZIKXJKkHmeAlSepBJnhJknqQCV6SpB60d90BtGLWrFk5NDRUdxhdac2aNQAsWLCg5kgkSe1yzz33PJGZB5Y5dkon+KGhIVavXl13GF1p0aJFAKxatarWOCRJ7RMRvy97rF30kiT1oCndgtfUdPOa9S/aP2PB7LYeL0myBS9JUk+yBS9J6ivbtm2j0WiwZcuWukPZrYGBAQYHB5k+ffqkr2GCV+1a7YK3C1/SRDQaDWbMmMHQ0BARUXc4u8hMNm7cSKPRYN68eZO+jl30kqS+smXLFmbOnNmVyR0gIpg5c2bLPQwmeElS3+nW5D6iHfHZRa++Y5e+pH5ggpck9bWdv/S3qmyj4fbbb+dDH/oQO3bs4IILLmDZsmVtjcMuekmSOmzHjh1cdNFFfP/73+ehhx7i+uuv56GHHmrrPWzBq3Lt/nYsSVPdXXfdxV/91V9x+OGHA3DOOedwyy23cNRRR7XtHrUk+Ih4BHga2AFsz8zhiDgA+AYwBDwCnJ2Zf6ojPqndHPeXNNof/vAHDj300D/vDw4O8otf/KKt92ipiz4ijm7h9Ddk5msyc7jYXwbcmZnzgTuLfUmSek5m7lLW7pn9rbbgvxQRLwG+Cnw9M59s4VqnAYuK7WuAVcAlrQSnqckufUm9bnBwkMcee+zP+41Gg0MOOaSt92ipBZ+ZJwHvAg4FVkfE1yNicZlTgf+IiHsiYmlRdnBmri+uux44aKwTI2JpRKyOiNUbNmxoJXxJkmpx3HHH8fDDD/O73/2OrVu3csMNN3Dqqae29R4tj8Fn5sMRcRmwGvgccEw0+xkuzcybd3PaiZm5LiIOAlZGxG8mcL/lwHKA4eHhXfs4JEmagDrmxOy99958/vOf52//9m/ZsWMH733ve/nrv/7r9t6jlZMj4lXAecBbgJXA2zLz3og4BPgZMGaCz8x1xc/HI+LbwGuBP0bE7MxcHxGzgcdbiU2SpG62ZMkSlixZUtn1W23Bfx64mmZr/bmRwqJ1ftlYJ0TES4G9MvPpYvu/Af8IrADOBa4oft7SYmxqg26c/T3eGH3VY/jj1Uk77t+N9S5pamk1wS8BnsvMHQARsRcwkJmbM/O63ZxzMPDtYrbg3jQn590eEXcDN0bE+cCjwFktxqYKlElevZaMnPQnaSpqNcHfAbwZeKbY3xf4D+C/7O6EzPwt8OoxyjcCb2oxHrXIZCapH2RmV79wZqzH6Caq1aVqBzJzJLlTbO/b4jUlSarMwMAAGzdubEsSrcLI++AHBgZauk6rLfhnI2JhZt4LEBHHAs+Nc44kSbUZHByk0WjQzY9aDwwMMDg42NI1Wk3wFwM3RcS6Yn828I4WrylJUmWmT5/OvHnz6g6jci0l+My8OyKOABYAAfwmM7e1JTKpJs5DkNQL2vGymeNoviBmb5qL3JCZ17bhupIkaZJaXejmOuCVwP003wwHzWVoTfBThK1VSepNrbbgh4GjslunIkqS1KdaTfAPAq8AbAZ2iZEW+RObt9YciSSpTq0m+FnAQxFxF/D8SGFmtveVOJIkaUJaTfCXtyMISZLUXq0+JvejiDgMmJ+Zd0TEvsC09oQmdYYTDSX1olZn0V8ILAUOoDmbfg7wJVxTvq+ZMKvn2+YkjafVLvqLaL7L/RcAmflwRBzUclRqGxNB9SbzhcYvQZKq1mqCfz4zt468kSci9qb5HLykNvILgaSJajXB/ygiLgX2iYjFwPuB77YelqpiopCk/tBqgl8GnA88ALwPuA34cqtBSWovh2qk/tPqLPoXgKuLjyRJ6hKtzqL/HWOMuWfm4a1cV5IktaYda9GPGADOovnInCRJqtFerZycmRtHff6QmZ8F3tim2CRJ0iS12kW/cNTuXjRb9DPGOedQmq+TfQXwArA8M6+MiMuBC4ENxaGXZuZtrcTXD5wVr8lw0p3U+1rtov/0qO3twCPA2eOcsx34SGbeGxEzgHsiYmXxu/+RmZ9qMSap75iwJe2s1Vn0b5jEOespXi+bmU9HxK9pLnGrMfgPt6Yi/95K9Wu1i/7De/p9Zn5mnPOHgGNoLnV7IvCBiHg3sJpmK/9PrcQnSVK/ammSHc0x9/9OswU+B/gH4Cia4/DjjcXvB3wLuDgzNwFfpPnCmtfQbOF/ejfnLY2I1RGxesOGDWMdIklS32t1DH4WsDAznwYoJsrdlJkX7OmkiJhOM7n/e2beDJCZfxz1+6uBW8c6NzOXA8sBhoeHXfdekqQxtJrg5wJbR+1vBYb2dEI030zzr8CvR3fhR8TsYnwe4HTgwRZjk1SSY+ZS72k1wV8H3BUR36a5ot3pNB+B25MTgb8HHoiI+4uyS4F3RsRrius8QnNt+57nY26SpCq0Oov+kxHxfeB1RdF5mXnfOOf8BIgxfuUz71KbtPrF0Ra9NPW12oIH2BfYlJn/FhEHRsS8zPxdG67bE/yHUpJUh5Zm0UfEx4FLgI8WRdOBr7UalCRJak2rLfjTaT7Hfi9AZq4rVqdTRRyzVzfy76XUfVp9Dn5rZibFK2Mj4qWthyRJklrVaoK/MSKuAvaPiAuBO4CrWw9LkiS1otVZ9J+KiMXAJmAB8LHMXDnOaZKmOLvkpe436QQfEdOAH2TmmwGTutTDTOjS1DPpLvrM3AFsjoiXtzEeSZLUBq3Oot9Cc0W6lcCzI4WZ+cEWryuph4zVA+CaEFK1Wk3w3ys+faEd/0jZ1SmV4yJRUmsmleAjYm5mPpqZ17Q7oG5iMpYkTVWTbcF/B1gIEBHfyswz2xfS1OaXAmly/H9Haq/JJvjRL4s5vB2BSNJEjPeFwC599bvJJvjczbYkdYXxxvAd41evm2yCf3VEbKLZkt+n2KbYz8x8WVuikyRJkzKpBJ+Z09odiKT+MtEx93a/436839ui11TX6lr0kiSpC7X6HLwk9SQn8WmqM8GPMpkuQB/tkQR28av7mOAlqQuUWSlzol8i/NLR30zwkjQJ/Thprxf/TL2sqybZRcTJEbEmItZGxLK645EkaarqmhZ88X75LwCLgQZwd0SsyMyH6o1MklpXRevXFrX2pGsSPPBaYG1m/hYgIm4ATgNM8JJ6TpkJuu2exDvRJwNaXatgonMExounHfesWjfF000Jfg7w2Kj9BnD8zgdFxFJgabH7TESs6UBsU9aZRxwy3iFzgUc7EIrGZv3Xx7qvj3U/eYeVPbCbEnyMUbbLOveZuRxYXn04/SEiNmTmcN1x9Cvrvz7WfX2s+87opkl2DeDQUfuDwLqaYuknT9YdQJ+z/utj3dfHuu+AbkrwdwPzI2JeRLwEOAdYUXNM/eCpugPoc9Z/faz7+lj3HdA1XfSZuT0iPgD8AJgGfCUzf1VzWP3A4Y56Wf/1se7rY913QGT6OndJknpNN3XRS5KkNjHBS5LUg0zwkiT1IBO8JEk9yAQvSVIPMsFLktSDTPCSJPUgE7wkST3IBC9JUg/qmqVqJ2PWrFk5NDRUdxiqyZo1zTcFL1iwoOZIJKkz7rnnnicy88Ayx1aW4CPiUOBa4BXAC8DyzLwyIg4AvgEMAY8AZ2fmnyIigCuBJcBm4D2Zee+e7jE0NMTq1aur+iOoyy1atAiAVatW1RqHJHVKRPy+7LFVdtFvBz6SmUcCJwAXRcRRwDLgzsycD9xZ7AOcAswvPkuBL1YYmyRJPa2yFnxmrgfWF9tPR8SvgTnAacCi4rBrgFXAJUX5tdl8+83PI2L/iJhdXEc97OY1L/5PfMaC2TVFIkm9oyOT7CJiCDgG+AVw8EjSLn4eVBw2B3hs1GmNomznay2NiNURsXrDhg1Vhi1J0pRV+SS7iNgP+BZwcWZuag61j33oGGW7vMs2M5dTvEt4eHjYd91KkiZk27ZtNBoNtmzZUncouzUwMMDg4CDTp0+f9DUqTfARMZ1mcv/3zLy5KP7jSNd7RMwGHi/KG8Cho04fBNZVGZ8kqf80Gg1mzJjB0NAQe2h01iYz2bhxI41Gg3nz5k36OpV10Rez4v8V+HVmfmbUr1YA5xbb5wK3jCp/dzSdADzl+Lskqd22bNnCzJkzuzK5A0QEM2fObLmHocoW/InA3wMPRMT9RdmlwBXAjRFxPvAocFbxu9toPiK3luZjcudVGJskqY91a3If0Y74qpxF/xPGHlcHeNMYxydwUVXxSJLUT6b0SnbqTT42J6mTdv43p1Vl/s1673vfy6233spBBx3Egw8+2Nb7j3AtekmSOuw973kPt99+e6X3MMFLktRhr3/96znggAMqvUepBB8RR1cahSRJaquyY/BfioiXAF8Fvp6ZT1YXknpdu8e7JEm7KtWCz8yTgHfRXIhmdUR8PSIWVxqZJEmatNKz6DPz4Yi4DFgNfA44pljM5tJRq9RJbeesekmauFIJPiJeRXPhmbcAK4G3Zea9EXEI8DPABC9JmpLqaDS8853vZNWqVTzxxBMMDg7yiU98gvPPP7+t9yjbgv88cDXN1vpzI4WZua5o1UuSpJKuv/76yu9RNsEvAZ7LzB0AEbEXMJCZmzPzusqiU09wUp0kdV7Z5+DvAPYZtb9vUSZJkrpQ2QQ/kJnPjOwU2/tWE5IkSdVqvv6ke7UjvrJd9M9GxMLMvBcgIo4FnhvnHPUpu+QldbOBgQE2btzYta+MHXkf/MDAQEvXKZvgLwZuioh1xf5s4B0t3VmSpBoMDg7SaDTYsGFD3aHs1sDAAIODgy1do1SCz8y7I+IIYAHNV8D+JjO3tXRnSZJqMH36dObNm1d3GJWbyOtijwOGinOOiQgy89pKotKUYXe8JHWnsgvdXAe8Ergf2FEUJ2CClySpC5VtwQ8DR2W3TzuUJElA+cfkHgReUWUgkiSpfcq24GcBD0XEXcDzI4WZeWolUUmSpJaUTfCXVxmENBEjE/ue2Ly15kgkqXuVfUzuRxFxGDA/M++IiH2BadWGpm7krHlJmhpKjcFHxIXAN4GriqI5wHeqCkqSJLWm7CS7i4ATgU0AmfkwcFBVQUmSpNaUTfDPZ+afBzwjYm+az8FLkqQuVDbB/ygiLgX2iYjFwE3Ad6sLS5IktaLsLPplwPnAA8D7gNuAL+/phIj4CvBW4PHMPLooOwD4Bs0lbx8Bzs7MP0XzdT5XAkuAzcB7Rt5cJ41n54l/ZyyYXVMkktQ9SrXgM/OFzLw6M8/KzLcX2+N10X8VOHmnsmXAnZk5H7iz2Ac4BZhffJYCXyz7B5AkSbsquxb97xhjzD0zD9/dOZn544gY2qn4NGBRsX0NsAq4pCi/tvjS8POI2D8iZmemz2RJkjQJE1mLfsQAcBZwwCTud/BI0s7M9RExMhN/DvDYqOMaRZkJXpKkSSjbRb9x1OcPmflZ4I1tjCPGuu2YB0YsjYjVEbF6w4YNbQxBkqTeUbaLfuGo3b1otuhnTOJ+fxzpeo+I2cDjRXkDOHTUcYPAurEukJnLgeUAw8PDPqonSdIYynbRf3rU9naKGfCTuN8K4FzgiuLnLaPKPxARNwDHA085/i5J0uSVXYv+DRO9cERcT3NC3ayIaAAfp5nYb4yI84FHaY7lQ/OxuyXAWpqPyZ030ftJkqT/o2wX/Yf39PvM/MwYZe/czeFvGuPYpLkcriRJaoOJzKI/jmZXOsDbgB/z4pnvkiSpS5RN8LOAhZn5NEBEXA7clJkXVBWYJEmavLIJfi6wddT+VprLzUpdx6VrJal8gr8OuCsivk3z+fTTgWsri0pdY+dkORWZ8CX1o7Kz6D8ZEd8HXlcUnZeZ91UXliRJakXZ18UC7AtsyswrgUZEzKsoJkmS1KJSCT4iPk7zpTAfLYqmA1+rKihJktSasi3404FTgWcBMnMdk1uqVpIkdUDZBL+1WIwmASLipdWFJEmSWlU2wd8YEVcB+0fEhcAdwNXVhSVJklpRdhb9pyJiMbAJWAB8LDNXVhqZJEmatHETfERMA36QmW8GTOqSJE0B43bRZ+YOYHNEvLwD8UiSpDYou5LdFuCBiFhJMZMeIDM/WElUqk0vrFwnSSqf4L9XfCRJ0hSwxwQfEXMz89HMvKZTAUmSpNaNNwb/nZGNiPhWxbFIkqQ2Ga+LPkZtH15lIFKn+HY5Sf1gvASfu9mWeoYJX1IvGi/BvzoiNtFsye9TbFPsZ2a+rNLoJEnSpOwxwWfmtE4Fonr4WJwk9aaJvA9ekiRNESZ4SZJ6UNmFbtQj7JKXpP5gC16SpB5kC17ayXi9HD5GJ2kqMMFLE+Rz85Kmgq5K8BFxMnAlMA34cmZeUXNIU55j7pLUn7omwUfENOALwGKgAdwdESsy86F6I+tuJvD62aKX1I26JsEDrwXWZuZvASLiBuA0wASvKWWsL10mfUmd1k0Jfg7w2Kj9BnD8zgdFxFJgabH7TESs6UBsvWwu8GjdQbTizCMOqTuEVkz5+p/CrPv6WPeTd1jZA7spwccYZbu84CYzlwPLqw+nP0TEhswcrjuOfmX918e6r4913xnd9Bx8Azh01P4gsK6mWPrJk3UH0Oes//pY9/Wx7jugmxL83cD8iJgXES8BzgFW1BxTP3iq7gD6nPVfH+u+PtZ9B3RNF31mbo+IDwA/oPmY3Fcy81c1h9UPHO6ol/VfH+u+PtZ9B0TmLsPckiRpiuumLnpJktQmJnhJknqQCV6SpB5kgpckqQeZ4CVJ6kEmeEmSepAJXpKkHmSClySpB5ngJUnqQV2zVO1kzJo1K4eGhuoOQ8CaNc239i5YsKDmSCSpd91zzz1PZOaBZY6d0gl+aGiI1atX1x2GgEWLFgGwatWqWuOQpF4WEb8ve6xd9JIk9aAp3YJXf7h5zfoX7Z+xYHZNkUjS1GELXpKkHmQLXpLUV7Zt20aj0WDLli11h7JbAwMDDA4OMn369ElfwwQvSeorjUaDGTNmMDQ0RETUHc4uMpONGzfSaDSYN2/epK9jglfX2XnMXZLaacuWLV2b3AEigpkzZ7Jhw4aWrlPZGHxEfCUiHo+IB0eVHRARKyPi4eLnXxblERGfi4i1EfHLiFhYVVySJHVrch/RjviqnGT3VeDkncqWAXdm5nzgzmIf4BRgfvFZCnyxwrgkSep5lXXRZ+aPI2Jop+LTgEXF9jXAKuCSovzazEzg5xGxf0TMzkz7aiVJlWr3sGCZR3kfe+wx3v3ud/Of//mf7LXXXixdupQPfehDbY2j02PwB48k7cxcHxEHFeVzgMdGHdcoynap9YhYSrOVz9y5c6uNVpKkCuy99958+tOfZuHChTz99NMce+yxLF68mKOOOqpt9+iW5+DHGmzIsQ7MzOWZOZyZwwceWGo5XkmSusrs2bNZuLA53WzGjBkceeSR/OEPf2jrPUol+Ig4uk33+2NEzC6uORt4vChvAIeOOm4QWNeme0qS1LUeeeQR7rvvPo4//vi2XrdsC/5LEXFXRLw/IvZv4X4rgHOL7XOBW0aVv7uYTX8C8JTj75KkXvfMM89w5pln8tnPfpaXvexlbb12qTH4zDwpIuYD7wVWR8RdwL9l5srdnRMR19OcUDcrIhrAx4ErgBsj4nzgUeCs4vDbgCXAWmAzcN7k/jjqR65VL2kq2rZtG2eeeSbvete7OOOMM9p+/dKT7DLz4Yi4DFgNfA44JpoP6l2amTePcfw7d3OpN41xbAIXlY1F3c2EK0l7lpmcf/75HHnkkXz4wx+u5B6lEnxEvIpmq/otwErgbZl5b0QcAvwM2CXBS5I0FdTRCPnpT3/Kddddx9/8zd/wmte8BoB/+qd/YsmSJW27R9kW/OeBq2m21p8bKczMdUWrXiqt1Rb+eM+s2oMgqduddNJJNDuvq1M2wS8BnsvMHQARsRcwkJmbM/O6yqJTT3BteUnqvLIJ/g7gzcAzxf6+wH8A/6WKoNRf/AIgSe1X9jG5gcwcSe4U2/tWE5IkSdWqunu8Ve2Ir2yCf3b0G94i4ljguT0cL0lSVxoYGGDjxo1dm+RH3gc/MDDQ0nXKdtFfDNwUESOry80G3tHSnSVJqsHg4CCNRqPl961XaWBggMHBwZauUXahm7sj4ghgAc1143+TmdtaurNUE2fZS/1t+vTpzJs3r+4wKjeRt8kdBwwV5xwTEWTmtZVEJUmSWlJ2oZvrgFcC9wM7iuIETPCa8mzRS+pFZVvww8BR2a0zEiRJ0ouUTfAPAq8AfGC5z9nalaSpoWyCnwU8VLxF7vmRwsw8tZKopC7ilxpJU1HZBH95lUFo6hpJfk9s3vqifUlSvco+JvejiDgMmJ+Zd0TEvsC0akOTJEmTVWolu4i4EPgmcFVRNAf4TlVBSZKk1pRdqvYi4ERgE0BmPgwcVFVQkiSpNWXH4J/PzK0RAUBE7E3zOXip67V7XoCT7iRNBWUT/I8i4lJgn4hYDLwf+G51YUn1caKgpF5QNsEvA84HHgDeB9wGfLmqoKSpxBa9pG5Udhb9C8DVxUeSJHW5smvR/44xxtwz8/C2R6SOGq/1aXe1JE1NE1mLfsQAcBZwQPvDkSRJ7VC2i37jTkWfjYifAB+bzE0j4hHgaZpvptuemcMRcQDwDZqvpH0EODsz/zSZ62vybLFLUm8o20W/cNTuXjRb9DNavPcbMvOJUfvLgDsz84qIWFbsX9LiPSRJ6ktlu+g/PWp7O0ULu82xnAYsKravAVZhgpckaVLKdtG/oc33TeA/IiKBqzJzOXBwZq4v7rc+IsZcKS8ilgJLAebOndvmsCRJ6g1lu+g/vKffZ+ZnJnjfEzNzXZHEV0bEb8qeWHwZWA4wPDzsanqSJI1hIrPojwNWFPtvA34MPDaZm2bmuuLn4xHxbeC1wB8jYnbRep8NPD6Za0uSpPIJfhawMDOfBoiIy4GbMvOCid4wIl4K7JWZTxfb/w34R5pfHs4Frih+3jLRa0uSpKayCX4usHXU/laaj7NNxsHAt4sX1+wNfD0zb4+Iu4EbI+J84FGaz9qrzXwMTpL6Q9kEfx1wV9GdnsDpwLWTuWFm/hZ49RjlG4E3TeaakiTpxcrOov9kRHwfeF1RdF5m3lddWNLUNVYviS+gkdRpe03g2H2BTZl5JdCIiHkVxSRJklpUKsFHxMdpLjrz0aJoOvC1qoKSJEmtKTsGfzpwDHAvNB9zi4hWl6qV+obvjJfUaWW76LdmZlK8MrZ4vE2SJHWpsgn+xoi4Ctg/Ii4E7gCuri4sSZLUirKz6D8VEYuBTcAC4GOZubLSyNQWPvcuSf1p3AQfEdOAH2TmmwGTuiRJU8C4XfSZuQPYHBEv70A8kiSpDcrOot8CPBARK4FnRwoz84OVRCVJklpSNsF/r/ioy/j4lSRpLHtM8BExNzMfzcxrOhWQWuOkuqnJL2qS2m28Fvx3gIUAEfGtzDyz+pCk3ucXMUlVG2+SXYzaPrzKQCRJUvuMl+BzN9uSJKmLjddF/+qI2ESzJb9PsU2xn5n5skqjkwQ4Ri9p4vaY4DNzWqcC0dj8h12SNBllH5OT1EFOwpPUKhP8FOM//JKkMsq+TU6SJE0htuC7jC10SVI7mOClHjTeF0Una0q9zwQv9QB7fiTtrKsSfEScDFwJTAO+nJlX1BxS2/kPsdrBv0eSxtM1CT4ipgFfABYDDeDuiFiRmQ/VG1lr/IdY3cgufKn3dU2CB14LrM3M3wJExA3AaUBtCd5FZtSvJvrFdLz/N8a6nv8/SdXqpgQ/B3hs1H4DOH7ngyJiKbC02H0mItZ0ILZeNhd4tF0XO/OIQ9p1qX7R1vrXhFj39bHuJ++wsgd2U4KPMcp2ecFNZi4HllcfTn+IiA2ZOVx3HP3K+q+PdV8f674zummhmwZw6Kj9QWBdTbH0kyfrDqDPWf/1se7rY913QDcl+LuB+RExLyJeApwDrKg5pn7wVN0B9Dnrvz7WfX2s+w7omi76zNweER8AfkDzMbmvZOavag6rHzjcUS/rvz7WfX2s+w6IzF2GuSVJ0hTXTV30kiSpTUzwkiT1IBO8JEk9yAQvSVIPMsFLktSDTPCSJPUgE7wkST2osgQfEYdGxP+MiF9HxK8i4kNF+QERsTIiHi5+/mVRHhHxuYhYGxG/jIiFVcUmSVKvq7IFvx34SGYeCZwAXBQRRwHLgDszcz5wZ7EPcAowv/gsBb5YYWySJPW0ypaqzcz1wPpi++mI+DXNV8KeBiwqDrsGWAVcUpRfm82l9X4eEftHxOziOmOaNWtWDg0NVfVHkCq1Zk3zTccLFiyoORJJU8U999zzRGYeWObYjqxFHxFDwDHAL4CDR5J2Zq6PiIOKw8Z6H/wcii8Jo6715/fBz507l9WrV1cau1SVRYsWAbBq1apa45A0dUTE78seW/kku4jYD/gWcHFmbtrToWOUjfk++MwczszhAw8s9SVGkqS+U2kLPiKm00zu/56ZNxfFfxzpeo+I2cDjRbnvg5cm6eY1Lx7JOmPB7JoikdQtqpxFH8C/Ar/OzM+M+tUK4Nxi+1zgllHl7y5m058APLWn8XdJkrR7VbbgTwT+HnggIu4vyi4FrgBujIjzgUeBs4rf3QYsAdYCm4HzKoxNktSntm3bRqPRYMuWLXWHslsDAwMMDg4yffr0SV+jyln0P2HscXWAN41xfAIXVRWP1M/swpf+j0ajwYwZMxgaGqLZ2dxdMpONGzfSaDSYN2/epK/jSnaSpL6yZcsWZs6c2ZXJHSAimDlzZss9DCZ4SVLf6dbkPqId8XXkOXhJ3cUue6n3meAlSX1t5y+8rSrzhXnLli28/vWv5/nnn2c4eWZrAAATb0lEQVT79u28/e1v5xOf+ERb4zDBS5LUYX/xF3/BD3/4Q/bbbz+2bdvGSSedxCmnnMIJJ5zQtns4Bi9JUodFBPvttx/QfGxv27ZtbZ8XUKoFHxFHZ+aDbb2zpMq0u8tRUvvt2LGDY489lrVr13LRRRdx/PHHt/X6ZVvwX4qIuyLi/RGxf1sjkCSpD02bNo3777+fRqPBXXfdxYMPtrcdXaoFn5knRcR84L3A6oi4C/i3zFzZ1mgkldLuFrqz6qX67L///ixatIjbb7+do48+um3XLT0Gn5kPA5fRfHf7fwU+FxG/iYgz2haNJEl9YMOGDTz55JMAPPfcc9xxxx0cccQRbb1H2TH4V9FcG/4twErgbZl5b0QcAvwMuHlP50uS1K3q6LFav3495557Ljt27OCFF17g7LPP5q1vfWtb71H2MbnPA1cDl2bmcyOFmbkuIi5ra0SSJPW4V73qVdx3332V3qNsgl8CPJeZOwAiYi9gIDM3Z+Z1lUUnSZImpewY/B3APqP29y3KJElSFyqb4Acy85mRnWJ732pCkiSpWs03lHevdsRXNsE/GxELR3Yi4ljguT0cL0lSVxoYGGDjxo1dm+RH3gc/MDDQ0nXKjsFfDNwUEeuK/dnAO1q6syRJNRgcHKTRaLBhw4a6Q9mtgYEBBgcHW7pG2YVu7o6II4AFQAC/ycxtLd1ZkqQaTJ8+nXnz5tUdRuUm8ja544Ch4pxjIoLMvLaSqCRJUkvKLnRzHfBK4H5gR1GcgAle6oBOvzzGpWulqa9sC34YOCq7dUaCJEl6kbKz6B8EXlFlIJIkqX3KtuBnAQ8Vb5F7fqQwM0+tJCpJktSSsgn+8iqDkCRJ7VX2MbkfRcRhwPzMvCMi9gWmVRua1L86PalOUu8pNQYfERcC3wSuKormAN+pKihJktSaspPsLgJOBDYBZObDwEFVBSVJklpTNsE/n5lbR3YiYm+az8FLkqQuVDbB/ygiLgX2iYjFwE3Ad/d0QkR8JSIej4gHR5UdEBErI+Lh4udfFuUREZ+LiLUR8cvRL7aRJEkTVzbBLwM2AA8A7wNuAy4b55yvAiePcZ07M3M+cGexD3AKML/4LAW+WDIuSZI0hrKz6F8Ari4+pWTmjyNiaKfi04BFxfY1wCrgkqL82mKlvJ9HxP4RMTsznUosSdIklF2L/neMMeaemYdP8H4HjyTtzFwfESMT9eYAj406rlGU7ZLgI2IpzVY+c+fOneDtJUnqDxNZi37EAHAWcEAb44gxysacxJeZy4HlAMPDw070kyRpDKXG4DNz46jPHzLzs8AbJ3G/P0bEbIDi5+NFeQM4dNRxg8C6SVxfkiRRfqGbhaM+wxHxD8CMSdxvBXBusX0ucMuo8ncXs+lPAJ5y/F2SpMkr20X/6VHb24FHgLP3dEJEXE9zQt2siGgAHweuAG6MiPOBR2l29UNzVv4SYC2wGTivZFySJGkMZWfRv2GiF87Md+7mV28a49ikuVqe1Jdce15Su5WdRf/hPf0+Mz/TnnAkSVI7TGQW/XE0x8oB3gb8mBc/2iapR+3cw3DGgtk1RSKprLIJfhawMDOfBoiIy4GbMvOCqgKTJEmTV3ap2rnA1lH7W4GhtkcjSZLaomwL/jrgroj4Ns0FaE4Hrq0sKkmS1JKys+g/GRHfB15XFJ2XmfdVF5YkSWpF2RY8wL7Apsz8t4g4MCLmZebvqgpM6mU3r1nPE5u3/nl7qnHSndT9yq5k93Gab337aFE0HfhaVUFJkqTWlJ1kdzpwKvAsQGauY3JL1UqSpA4om+C3FqvNJUBEvLS6kCRJUqvKJvgbI+IqYP+IuBC4A7i6urAkSVIrys6i/1RELAY2AQuAj2XmykojkyRJkzZugo+IacAPMvPNgEldkqQpYNwEn5k7ImJzRLw8M5/qRFCSphYfm5O6T9nn4LcAD0TESoqZ9ACZ+cFKopIkSS0pm+C/V3wkTcJUXMxG0tS2xwQfEXMz89HMvKZTAUmSpNaN14L/DrAQICK+lZlnVh+SNLXZWpfUDcZL8DFq+/AqA5HUO5x0J9VvvIVucjfbkiSpi43Xgn91RGyi2ZLfp9im2M/MfFml0UmSpEnZY4LPzGmdCkSSJLXPRN4HL2kMTqqT1I1M8JJq4UQ8qVpl3yYnSZKmEFvw0gTZJT9x1pnUebbgJUnqQbbgJXWF8Vr5jtFLE9NVLfiIODki1kTE2ohYVnc8kiRNVV3Tgo+IacAXgMVAA7g7IlZk5kP1RqZ+5/ixpKmoaxI88FpgbWb+FiAibgBOA0zwkib8RcsuffW7bkrwc4DHRu03gON3PigilgJLi91nImJNB2LrZXOBR+sOoo/NPfOIQ6z/evh3vz7W/eQdVvbAbkrwMUbZLi+4yczlwPLqw+kPEbEhM4frjqNfWf/1se7rY913RjdNsmsAh47aHwTW1RRLP3my7gD6nPVfH+u+PtZ9B3RTgr8bmB8R8yLiJcA5wIqaY+oHT9UdQJ+z/utj3dfHuu+Arumiz8ztEfEB4AfANOArmfmrmsPqBw531Mv6r491Xx/rvgMic5dhbkmSNMV1Uxe9JElqExO8JEk9yAQvSVIPMsFLktSDTPCSJPUgE7wkST3IBC9JUg8ywUuS1INM8JIk9aCuWap2MmbNmpVDQ0N1h9FRa9Y03467YMGCmiORJHXaPffc80RmHljm2Cmd4IeGhli9enXdYXTUokWLAFi1alWtcUiSOi8ifl/2WLvoJUnqQVO6Ba9d3bxm/Yv2z1gwu6ZIJEl1MsH3OBO+JPUnE7wkqa9s27aNRqPBli1b6g5ltwYGBhgcHGT69OmTvkZlCT4iDgWuBV4BvAAsz8wrI+IA4BvAEPAIcHZm/ikiArgSWAJsBt6TmfdWFZ8kqT81Gg1mzJjB0NAQzdTTXTKTjRs30mg0mDdv3qSvU2ULfjvwkcy8NyJmAPdExErgPcCdmXlFRCwDlgGXAKcA84vP8cAXi5/ag5274CVJe7Zly5auTe4AEcHMmTPZsGFDS9epLMFn5npgfbH9dET8GpgDnAYsKg67BlhFM8GfBlybmQn8PCL2j4jZxXXUJo7JSxJdm9xHtCO+jjwmFxFDwDHAL4CDR5J28fOg4rA5wGOjTmsUZTtfa2lErI6I1a1+u5EkqVdVPskuIvYDvgVcnJmb9vCtZKxf5C4FmcuB5QDDw8O7/F6SpIlo91DnRHpGd+zYwfDwMHPmzOHWW29taxyVtuAjYjrN5P7vmXlzUfzHiJhd/H428HhR3gAOHXX6ILCuyvgkSarTlVdeyZFHHlnJtStL8MWs+H8Ffp2Znxn1qxXAucX2ucAto8rfHU0nAE85/i5J6lWNRoPvfe97XHDBBZVcv1QXfUQcnZkPTvDaJwJ/DzwQEfcXZZcCVwA3RsT5wKPAWcXvbqP5iNxamo/JnTfB+0mSNGVcfPHF/Mu//AtPP/10JdcvOwb/pYh4CfBV4OuZ+eR4J2TmTxh7XB3gTWMcn8BFJeORJGnKuvXWWznooIM49thjK3t5WKku+sw8CXgXzTHy1RHx9YhYXElEkiT1uJ/+9KesWLGCoaEhzjnnHH74wx/yd3/3d229R+kx+Mx8GLiM5jPr/xX4XET8JiLOaGtE2qMnNm/lic1buXnNehe5kaQp6p//+Z9pNBo88sgj3HDDDbzxjW/ka1/7WlvvUXYM/lU0x8TfAqwE3lasUHcI8DPg5j2dL0lSt+rVBb/KjsF/HrgauDQznxspzMx1EXFZJZGpI1zZTpLqtWjRIhYtWtT265ZN8EuA5zJzB0BE7AUMZObmzLyu7VFJkqSWlB2DvwPYZ9T+vkWZJEnqQmUT/EBmPjOyU2zvW01IkiRVq/lkdvdqR3xlE/yzEbFwZCcijgWe28PxkiR1pYGBATZu3Ni1SX7kffADAwMtXafsGPzFwE0RMbI2/GzgHS3dWZKkGgwODtJoNFp+33qVBgYGGBwcbOkapRJ8Zt4dEUcAC2iuTvebzNzW0p0lSarB9OnTmTdvXt1hVG4ir4s9DhgqzjkmIsjMayuJSpIktaTsQjfXAa8E7gd2FMUJmOAlSepCZVvww8BR2a0zEnqYy9FKkiaj7Cz6B4FXVBmIJElqn7It+FnAQxFxF/D8SGFmnlpJVJIkqSVlE/zlVQYhSZLaq+xjcj+KiMOA+Zl5R0TsC0yrNjTVwZfPSFJvKDUGHxEXAt8EriqK5gDfqSooSZLUmrKT7C4CTgQ2AWTmw8BBVQUlSZJaUzbBP5+ZW0d2ImJvms/BS5KkLlQ2wf8oIi4F9omIxcBNwHerC0uSJLWibIJfBmwAHgDeB9wGXFZVUJIkqTVlZ9G/AFxdfCRJUpcruxb97xhjzD0zD297RJIkqWUTWYt+xABwFnDAnk6IiK8AbwUez8yji7IDgG/QfCvdI8DZmfmniAjgSmAJsBl4T2beW/6PIUmSRis1Bp+ZG0d9/pCZnwXeOM5pXwVO3qlsGXBnZs4H7iz2AU4B5hefpcAXS8YvSZLGULaLfuGo3b1otuhn7OmczPxxRAztVHwasKjYvgZYBVxSlF9bvK3u5xGxf0TMzkxfpSZJ0iSU7aL/9Kjt7RTd65O438EjSTsz10fEyGI5c4DHRh3XKMp2SfARsZRmK5+5c+dOIgRJknpf2Vn0b6g4jhjrtruJZTmwHGB4eNjFdiRJGkPZLvoP7+n3mfmZkvf740jXe0TMBh4vyhvAoaOOGwTWlbymJEnayURm0R8HrCj23wb8mBd3q5exAjgXuKL4ecuo8g9ExA3A8cBTjr93B98uJ0lTU9kEPwtYmJlPA0TE5cBNmXnB7k6IiOtpTqibFREN4OM0E/uNEXE+8CjNx+2guTLeEmAtzcfkzpvwn0SSJP1Z2QQ/F9g6an8rzWfZdysz37mbX71pjGOT5hvr+t7OLWZJkiajbIK/DrgrIr5Nc/Lb6cC1lUWlrmWXvSRNDWVn0X8yIr4PvK4oOi8z76suLEmS1Iqyb5MD2BfYlJlXAo2ImFdRTJIkqUWlEnxEfJzminMfLYqmA1+rKihJktSasi3404FTgWcBMnMd4yxVK0mS6lN2kt3WzMyISICIeGmFMWkKGWvWvxPvJKl+ZVvwN0bEVcD+EXEhcAdwdXVhSZKkVpSdRf+piFgMbAIWAB/LzJWVRiZJkiZt3AQfEdOAH2TmmwGTuiRJU8C4CT4zd0TE5oh4eWY+1Ymg+okr10mSqlB2kt0W4IGIWEkxkx4gMz9YSVSSJKklZRP894qPJEmaAvaY4CNibmY+mpnXdCogSZLUuvEek/vOyEZEfKviWCRJUpuM10Ufo7YPrzKQfuGkOklSJ4yX4HM329Ju+UpZSarfeAn+1RGxiWZLfp9im2I/M/NllUYnSZImZY8JPjOndSoQSZLUPhN5H7wkSZoiyj4HL02aY/KS1Hm24CVJ6kG24NVxtuglqXom+Ir53LskqQ520UuS1IO6KsFHxMkRsSYi1kbEsrrjkSRpquqaLvqImAZ8AVgMNIC7I2JFZj5Ub2QTY5f8xI1XZ47RS9LEdU2CB14LrM3M3wJExA3AaUBXJ3gTevVarWO/IEjqR92U4OcAj43abwDH73xQRCwFlha7z0TEmg7E1nXOPOKQdl1qLvBouy6mCbP+62Pd18e6n7zDyh7YTQk+xijb5QU3mbkcWF59OP0hIjZk5nDdcfQr678+1n19rPvO6KZJdg3g0FH7g8C6mmLpJ0/WHUCfs/7rY93Xx7rvgG5K8HcD8yNiXkS8BDgHWFFzTP3gqboD6HPWf32s+/pY9x3QNV30mbk9Ij4A/ACYBnwlM39Vc1j9wOGOeln/9bHu62Pdd0Bk7jLMLUmSprhu6qKXJEltYoKXJKkHmeD7xHjLAEfE6yPi3ojYHhFvryPGXlWi7j8cEQ9FxC8j4s6IKP2cq8ZXov7/ISIeiIj7I+InEXFUHXH2orLLj0fE2yMiI8JH59rIMfg+UCwD/L8YtQww8M7RywBHxBDwMuD/BlZk5jc7H2nvKVn3bwB+kZmbI+K/A4sy8x21BNxjStb/yzJzU7F9KvD+zDy5jnh7SZm6L46bAXwPeAnwgcxc3elYe5Ut+P7w52WAM3MrMLIM8J9l5iOZ+UvghToC7GFl6v5/ZubmYvfnNNeAUHuUqf9No3ZfyhgLbGlSxq37wv8L/AuwpZPB9QMTfH8YaxngOTXF0m8mWvfnA9+vNKL+Uqr+I+KiiPjfNBPNBzsUW68bt+4j4hjg0My8tZOB9QsTfH8otQywKlG67iPi74Bh4P+rNKL+UnYJ7C9k5iuBS4DLKo+qP+yx7iNiL+B/AB/pWER9xgTfH1wGuD6l6j4i3gz8P8Cpmfl8h2LrBxP9u38D8H9VGlH/GK/uZwBHA6si4hHgBGCFE+3axwTfH1wGuD7j1n3RTXkVzeT+eA0x9rIy9T9/1O5bgIc7GF8v22PdZ+ZTmTkrM4cyc4jm/JNTnWTXPib4PpCZ24GRZYB/DdyYmb+KiH8sZg0TEcdFRAM4C7gqIlwmuA3K1D3NLvn9gJuKR7X88tUmJev/AxHxq4i4H/gwcG5N4faUknWvCvmYnCRJPcgWvCRJPcgEL0lSDzLBS5LUg0zwkiT1IBO8JEk9yAQvSVIPMsFLktSD/n+z9D2P1orbywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.loc[:, :4].plot.hist(subplots=True, color='lightblue', bins=100, figsize=(8, 8));\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].axvline(guess_s[i], color='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5) Fit model to the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = {\n",
    "    'I': I,\n",
    "    'J': J,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'y': y,\n",
    "    'alpha': alpha, \n",
    "    'xi': xi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[1] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[3] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[5] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[7] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[9] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[11] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[13] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[15] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[17] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[19] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[21] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[23] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[25] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[27] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[29] is nan!\n",
      "WARNING:pystan:n_eff / iter for parameter prob_attr_class[31] is nan!\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[1] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[3] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[5] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[7] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[9] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[11] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[13] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[15] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[17] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[19] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[21] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[23] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[25] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[27] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[29] is nan!\n",
      "WARNING:pystan:Rhat for parameter prob_attr_class[31] is nan!\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    }
   ],
   "source": [
    "fit_real = sm.sampling(data=real_data, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(fit_real.extract(permuted=True), open('./../data/interim/post_samples.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples = pickle.load(open('./../data/interim/post_samples.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['nu', 'slip', 'guess', 'log_nu', 'prob_resp_class', 'prob_resp_attr', 'pi', 'log_items', 'prob_joint', 'prob_attr_class', 'lp__'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 536, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_mastery = post_samples['prob_resp_attr']\n",
    "student_mastery.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7922718544548545,\n",
       " 0.8237782229983325,\n",
       " 0.8086499641296334,\n",
       " 0.6068188795366777,\n",
       " 0.6326693582212178]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[student_mastery[:, :, i].mean() for i in range(student_mastery.shape[2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Further reading and watching\n",
    "\n",
    "- Statistical Rethinking by Richard McElreath\n",
    "\n",
    "- Bayesian Data Analysis 3 by Andrew Gelman *et al.*\n",
    "\n",
    "- Stan’s YouTube channel"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
